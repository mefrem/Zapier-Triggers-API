# Story 1.10: Load Testing and Performance Optimization

**Epic:** Epic 1: Build Zapier Triggers API MVP
**Story ID:** 1.10
**Status:** Ready for Review
**Priority:** High
**Story Points:** 13
**Sprint:** TBD

---

## User Story

**As a** Performance Engineer,
**I want** to validate system performance under load,
**so that** the API can handle production traffic.

---

## Context and Background

This story validates that the Triggers API can handle production-scale traffic with acceptable performance characteristics. While Stories 1.2-1.9 focused on functionality and observability, this story ensures the system meets non-functional requirements for latency, throughput, and reliability under stress.

Key performance targets from PRD:
- **Throughput:** 10,000 events/sec ingestion (POST /events)
- **Latency (POST /events):** p95 <100ms
- **Latency (GET /inbox):** p95 <50ms
- **Reliability:** <0.1% error rate under load
- **Scalability:** System auto-scales to handle traffic spikes

Load testing validates:
1. **System capacity:** Can handle peak traffic without degradation
2. **Bottlenecks:** Identifies performance constraints (Lambda, DynamoDB, SQS)
3. **Scaling effectiveness:** Auto-scaling policies work as expected
4. **Baseline establishment:** Documents performance under controlled load

**Dependencies:**
- Story 1.2: Event Ingestion Endpoint - POST /events implementation
- Story 1.3: Authentication and Authorization - API key generation
- Story 1.5: Event Inbox Endpoint - GET /inbox implementation
- Story 1.8: Monitoring - CloudWatch metrics and dashboards

**Related Documentation:**
- PRD Section 3: Non-Functional Requirements (NFR1: Performance, NFR2: Scalability)
- Architecture Section 3: Performance Requirements and Targets
- Architecture Section 8: DynamoDB Scaling and Optimization

---

## Acceptance Criteria

### 1. Load Test Achieves 10,000 Events/Sec Ingestion Rate
**Given** the Triggers API is deployed to staging environment
**When** a load test sends 10,000 POST /events requests per second
**Then** the API successfully ingests all events
**And** error rate remains <0.1%
**And** DynamoDB remains responsive (no throttling)
**And** p95 latency <100ms (even under sustained 10K req/sec)

**Implementation Notes:**
- Test duration: 5 minutes at 10,000 req/sec (3M total events)
- Load generation tool: Locust, k6, JMeter, or AWS Distributed Load Testing
- Load profile: Ramp up gradually (0 → 10K over 1 minute), sustain for 4 minutes
- Test data: Realistic event payloads (500-800 bytes each)
- Monitoring during test:
  - CloudWatch metrics (requests, errors, latency)
  - DynamoDB consumed write capacity (should be stable)
  - Lambda invocations and duration
  - SQS queue depth (should remain low)
- Success criteria:
  - Total events ingested: ≥2.98M (>99.3% of 3M)
  - Error rate: <0.1% (max 3000 errors)
  - p95 latency: <100ms
  - p99 latency: <300ms
  - No DynamoDB throttling errors observed

Example Locust test script:
```python
from locust import HttpUser, task, between
import json
import time
import uuid

class EventIngestionLoadTest(HttpUser):
    wait_time = between(0.001, 0.01)  # 1-10ms between requests

    def on_start(self):
        # Generate API key or use test key
        self.api_key = "sk_test_abc123"
        self.event_counter = 0

    @task
    def ingest_event(self):
        event_id = str(uuid.uuid4())
        payload = {
            "event_type": "order.created",
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S.000Z", time.gmtime()),
            "payload": {
                "order_id": f"order_{self.event_counter}",
                "user_id": f"user_{self.event_counter % 100}",
                "amount": 99.99,
                "items": [
                    {"sku": "ITEM-001", "qty": 1, "price": 99.99}
                ]
            }
        }

        headers = {
            "X-API-Key": self.api_key,
            "Content-Type": "application/json"
        }

        response = self.client.post(
            "/v1/events",
            json=payload,
            headers=headers,
            name="POST /events"
        )

        self.event_counter += 1
```

---

### 2. p95 Latency <100ms Under Load for POST /events
**Given** the load test is running at 10,000 req/sec
**When** latency is measured
**Then** p95 latency (95th percentile) is <100ms
**And** p99 latency is <300ms
**And** max latency doesn't exceed 5 seconds

**Implementation Notes:**
- Latency measurement: End-to-end (request sent → response received)
- Includes: Network latency, Lambda cold start (if applicable), DynamoDB write, response serialization
- Baseline expected breakdown:
  - DynamoDB write: ~8-10ms (p95)
  - Lambda processing: ~10-15ms
  - Network + overhead: ~5-10ms
  - Total: ~23-35ms (p95), leaving headroom to 100ms target
- Monitoring during test:
  - CloudWatch Latency metric (p95, p99, max)
  - X-Ray service map showing latency by component
  - Lambda Duration metric
  - DynamoDB SuccessfulRequestLatency metric
- Cold start handling:
  - If Lambda cold starts occur: Ensure <5% of requests
  - Cold start should not exceed 1 second
  - Warm Lambda latency: ~20-50ms p95

---

### 3. p95 Latency <50ms Under Load for GET /inbox
**Given** the load test is running with mixed workload (80% POST /events, 20% GET /inbox)
**When** GET /inbox latency is measured
**Then** p95 latency is <50ms
**And** p99 latency is <100ms
**And** Query consistently returns results within SLA

**Implementation Notes:**
- GET /inbox is read-only (faster than writes)
- Expected latency breakdown:
  - DynamoDB query (StatusIndex GSI): ~3-5ms p95
  - Response serialization: ~5-10ms
  - Network: ~5-10ms
  - Total: ~13-25ms p95 (well under 50ms target)
- Test data: 1000+ events in inbox (realistic backlog)
- Cursor pagination tested: Verify latency consistent across page 1, 5, 10
- Filtering tested: event_type filter doesn't impact latency
- Monitoring:
  - CloudWatch Latency metric for GET /inbox
  - DynamoDB query metrics (items scanned, items returned)
  - Query efficiency (items_scanned / items_returned ratio)

---

### 4. DynamoDB Auto-Scaling Handles Traffic Spikes
**Given** traffic suddenly increases from 1,000 to 10,000 req/sec
**When** auto-scaling policy is triggered
**Then** DynamoDB capacity increases automatically
**And** No throttling errors (ProvisionedThroughputExceededException)
**And** System recovers to <100ms p95 latency within 2 minutes

**Implementation Notes:**
- Auto-scaling configured before test:
  - Target utilization: 70% (room for spikes)
  - Scale-up threshold: If utilization >70% for 60 seconds, increase capacity
  - Scale-down threshold: If utilization <30% for 5 minutes, decrease capacity
- Spike test scenario:
  1. Baseline load: 1,000 req/sec for 1 minute
  2. Spike: Jump to 10,000 req/sec for 2 minutes
  3. Recovery: Drop back to 1,000 req/sec for 1 minute
- Monitoring:
  - DynamoDB ConsumedWriteCapacityUnits (should spike then stabilize)
  - DynamoDB ProvisionedWriteCapacityUnits (should increase)
  - CloudWatch Latency metric (should briefly spike, then normalize)
  - Error count (should remain near 0)
- Success: No throttling errors during spike recovery

---

### 5. Lambda Concurrency Limits Configured (Min: 10, Max: 1000)
**Given** the Lambda function is configured for production
**When** load test starts
**Then** Lambda concurrency is automatically managed:
- Reserved concurrency: 10 (minimum to ensure availability)
- Max concurrent executions: 1000
- Throttling: If concurrent invocations exceed 1000, requests queued and retried

**Implementation Notes:**
- Configuration via Terraform:
```hcl
resource "aws_lambda_function_url" "triggers_api" {
  function_name          = aws_lambda_function.triggers_api.function_name
  authorization_type     = "NONE"  # Authorization via custom authorizer
}

resource "aws_lambda_provisioned_concurrency_config" "triggers_api" {
  function_name                     = aws_lambda_function.triggers_api.function_name
  provisioned_concurrent_executions = 10
  qualifier                         = aws_lambda_alias.live.name
}

resource "aws_lambda_function_concurrency" "triggers_api" {
  function_name         = aws_lambda_function.triggers_api.function_name
  reserved_concurrency  = 1000
}
```
- Monitoring:
  - Lambda ConcurrentExecutions metric (should stay <1000)
  - Lambda Duration metric (should stay <100ms)
  - Lambda Errors metric (should stay near 0)
- Alerts:
  - If ConcurrentExecutions >900: Alert and consider scaling
  - If Duration >100ms: Alert and investigate
  - If Errors >0.1%: Alert immediately

---

### 6. Performance Test Suite Automated in CI/CD
**Given** code is merged to main branch
**When** CI/CD pipeline runs
**Then** automated performance tests execute:
- Smoke test: 100 req/sec for 30 seconds (ensures no regressions)
- Load test: 1,000 req/sec for 2 minutes (baseline validation)
- Spike test: Ramp from 100 to 5,000 req/sec (scaling validation)
- Full load test: 10,000 req/sec for 5 minutes (nightly only)

**Implementation Notes:**
- Integration with GitHub Actions or similar CI/CD:
```yaml
name: Performance Tests

on: [push, pull_request]

jobs:
  performance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Deploy to staging
        run: |
          # Deploy latest code to staging environment
          ./scripts/deploy-staging.sh

      - name: Run smoke test
        run: |
          locust -f load_tests/locustfile.py \
            --host https://staging-api.zapier.com \
            --users 10 --spawn-rate 2 --run-time 30s \
            --headless --only-summary

      - name: Run baseline load test
        run: |
          locust -f load_tests/locustfile.py \
            --host https://staging-api.zapier.com \
            --users 1000 --spawn-rate 50 --run-time 2m \
            --headless

      - name: Check performance results
        run: |
          python scripts/check_performance_results.py \
            --p95-latency 100 \
            --error-rate 0.1 \
            --min-throughput 9900

      - name: Upload results to S3
        if: always()
        run: |
          aws s3 cp results/ s3://performance-results/${{ github.sha }}/
```
- Nightly full load test:
  - Runs 10,000 req/sec test
  - Results saved and compared with historical baseline
  - Alerts if performance degrades >5%
- Results storage:
  - CloudWatch Logs: Detailed metrics
  - S3: Historical results for trend analysis
  - GitHub Issues: Automated alerts for regressions

---

### 7. Performance Baselines Documented
**Given** load tests are complete
**When** results are analyzed
**Then** performance baselines are documented:
- Throughput: 10,000+ events/sec
- Latency (POST /events): p95 <100ms, p99 <300ms
- Latency (GET /inbox): p95 <50ms, p99 <100ms
- Error rate: <0.1% under sustained load
- Cost per 1M events: Documented and tracked

**Implementation Notes:**
- Baseline document: `docs/performance/PERFORMANCE_BASELINE.md`
- Contents:
```markdown
# Performance Baseline Report

Date: 2025-11-11
Test Duration: 5 minutes sustained at 10K req/sec
Total Events Processed: 3,000,000
Error Count: 250 (0.008% error rate)

## Latency Results (POST /events)

| Percentile | Latency (ms) | Target (ms) | Status |
|------------|-------------|------------|---------|
| p50 | 18 | - | ✅ |
| p95 | 87 | <100 | ✅ |
| p99 | 267 | <300 | ✅ |
| p99.9 | 589 | - | ✅ |
| Max | 2156 | - | ✅ |

## Latency Results (GET /inbox)

| Percentile | Latency (ms) | Target (ms) | Status |
|------------|-------------|------------|---------|
| p50 | 15 | - | ✅ |
| p95 | 43 | <50 | ✅ |
| p99 | 89 | <100 | ✅ |

## Throughput

| Metric | Value | Status |
|--------|-------|--------|
| Requests sent | 3,000,000 | - |
| Successful responses | 2,999,250 | ✅ |
| Error responses | 250 | <0.1% ✅ |
| Sustained throughput | 10,000 req/sec | ✅ |

## Resource Utilization

| Service | Metric | Value | Capacity | Utilization |
|---------|--------|-------|----------|-------------|
| DynamoDB | Write Capacity (WCUs) | 850/sec avg | 1000 | 85% |
| Lambda | Concurrent Executions | 650 avg | 1000 | 65% |
| SQS | Queue Depth | 150 msgs avg | Unlimited | Low |
| Network | Outbound | 5.2 Gbps | 10 Gbps | 52% |

## Bottleneck Analysis

1. **DynamoDB Write Capacity (85% utilized)**
   - Capacity auto-scales from 400 to 1000 WCUs
   - No throttling observed
   - Recommendation: Monitor during production ramp

2. **Lambda Concurrency (65% utilized)**
   - Well under 1000 limit
   - No throttling observed
   - Headroom: 35% for traffic spikes

3. **Network Bandwidth (52% utilized)**
   - Event payloads average 750 bytes
   - Plenty of headroom for larger payloads

## Cost Analysis

Based on load test results:
- Cost per 1M events: $0.42 (Lambda: $0.15, DynamoDB: $0.27)
- Cost per 1K requests: $0.000420
- Monthly cost projection (100M events): $42
- Recommendation: Current pricing acceptable

## Performance vs. Targets

| Metric | Target | Achieved | Gap |
|--------|--------|----------|-----|
| Throughput | 10K/sec | 10K/sec | ✅ Met |
| p95 Latency (POST) | <100ms | 87ms | ✅ 13ms headroom |
| p95 Latency (GET) | <50ms | 43ms | ✅ 7ms headroom |
| Error Rate | <0.1% | 0.008% | ✅ Met |

## Next Steps

1. Production deployment with monitoring
2. Weekly performance reviews (first month)
3. Establish alert thresholds based on this baseline
4. Plan for 2x load test (20K/sec) in Q1
```
- Version control: Baseline tracked in git
- Historical tracking: New baseline created after major changes
- Regression detection: Automated alerts if new results differ >5%

---

## Integration Verification (IV)

### IV1: Load Test Successfully Ingests 10K Events/Sec with <100ms p95

**Verification Checklist:**
- [ ] Test executes without errors (infrastructure ready)
- [ ] Load ramps smoothly (0 → 10K over 1 minute)
- [ ] Sustained load holds for 4+ minutes
- [ ] Error rate <0.1% throughout test
- [ ] p95 latency <100ms (measured at 1M, 2M, 3M events)
- [ ] No DynamoDB throttling errors
- [ ] Lambda concurrency stays <1000
- [ ] Results reproducible (run test 3x, consistent results)

**How to Verify:**
```bash
# Run load test locally against staging
locust -f load_tests/locustfile.py \
  --host https://staging-api.zapier.com \
  --users 10000 --spawn-rate 3333 --run-time 5m \
  --headless --csv=results/load_test_results

# Analyze results
python scripts/analyze_results.py \
  --csv results/load_test_results_stats.csv \
  --p95-target 100 \
  --error-rate-target 0.001
```

---

### IV2: GET /inbox Queries Perform with <50ms p95 Latency

**Verification Checklist:**
- [ ] Baseline inbox contains 1000+ undelivered events
- [ ] Concurrent GET /inbox requests (1000+) don't timeout
- [ ] p95 latency <50ms across all percentiles
- [ ] p99 latency <100ms
- [ ] Query efficiency good (items scanned ≈ items returned)
- [ ] Pagination cursor performance consistent across pages

**How to Verify:**
```bash
# Run mixed workload test (80% POST, 20% GET)
locust -f load_tests/locustfile_mixed.py \
  --host https://staging-api.zapier.com \
  --users 5000 --spawn-rate 2500 --run-time 2m \
  --headless

# Check GET /inbox metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/Lambda \
  --metric-name Duration \
  --dimensions Name=FunctionName,Value=zapier-triggers-api \
  --start-time 2025-11-11T10:00:00Z \
  --end-time 2025-11-11T10:05:00Z \
  --period 60 \
  --statistics Average,Maximum
```

---

### IV3: Auto-Scaling Responds Correctly to Traffic Spikes

**Verification Checklist:**
- [ ] Spike from 1K → 10K req/sec triggers auto-scaling
- [ ] DynamoDB capacity increases within 2 minutes
- [ ] Lambda concurrent executions scale up smoothly
- [ ] No throttling errors during spike
- [ ] p95 latency remains <100ms after spike recovery
- [ ] System scales down after traffic drops

**How to Verify:**
```bash
# Run spike test
locust -f load_tests/locustfile_spike.py \
  --host https://staging-api.zapier.com \
  --headless

# Monitor DynamoDB metrics during test
aws cloudwatch tail \
  /aws/lambda/zapier-triggers-api \
  --follow \
  --filter "ConsumedWriteCapacityUnits"
```

---

### IV4: Performance Tests Integrated in CI/CD Pipeline

**Verification Checklist:**
- [ ] GitHub Actions workflow exists for performance tests
- [ ] Smoke test runs on every PR (<1 minute)
- [ ] Full load test runs nightly
- [ ] Results stored and accessible
- [ ] Regression detection alerts on >5% degradation
- [ ] Dashboard shows historical performance trends

**How to Verify:**
```bash
# Check CI/CD configuration
cat .github/workflows/performance-tests.yml

# View recent test results
gh action-runs list --workflow=performance-tests.yml --limit 10

# Check S3 results storage
aws s3 ls s3://performance-results/ --recursive
```

---

## Technical Implementation Details

### Technology Stack
- **Load Testing:** Locust (Python-based, scalable)
- **Monitoring:** CloudWatch, CloudWatch Logs Insights
- **Analysis:** Python pandas + matplotlib (performance reports)
- **CI/CD:** GitHub Actions + AWS Lambda/EC2 for load generation
- **Baseline Storage:** S3 + DynamoDB for historical tracking

### Implementation Architecture

```
load_tests/
├── locustfile.py (main load test)
├── locustfile_spike.py (spike test)
├── locustfile_mixed.py (mixed read/write test)
├── conftest.py (shared fixtures)
├── __init__.py
└── utils.py (helpers: event generation, result parsing)

scripts/
├── run_load_test.sh (local execution)
├── run_spike_test.sh
├── analyze_results.py (post-test analysis)
├── check_performance_results.py (validation against thresholds)
├── compare_baselines.py (trend analysis)
└── generate_report.py (baseline documentation)

.github/workflows/
├── performance-tests.yml (CI/CD integration)
└── nightly-load-test.yml (full load test)

docs/performance/
├── PERFORMANCE_BASELINE.md (documented baseline)
├── LOAD_TESTING_GUIDE.md (how to run tests)
└── PERFORMANCE_TARGETS.md (SLA documentation)

terraform/
├── cloudwatch.tf (dashboard for test results)
├── lambda.tf (concurrency configuration)
└── dynamodb.tf (auto-scaling policy)
```

### Key Implementation Patterns

1. **Gradual Load Ramp:** Slowly increase load to avoid cold starts skewing results
2. **Sustained Load:** Run at target load for 4+ minutes to detect degradation
3. **Spike Testing:** Validate auto-scaling recovery
4. **Mixed Workload:** 80/20 mix reflects real-world usage patterns
5. **Baseline Establishment:** Multiple runs to establish stable baseline
6. **Continuous Monitoring:** CloudWatch metrics captured throughout test
7. **Regression Detection:** Compare new results to historical baseline

---

## Testing Strategy

### Unit Tests (Locust Tasks)

```python
def test_event_payload_valid():
    # Ensure generated payloads match API schema

def test_correlation_id_propagation():
    # Verify correlation ID included in all requests

def test_error_handling():
    # Verify timeout and error scenarios handled
```

### Integration Tests (Full Workflow)

```python
def test_event_ingestion_flow():
    # Create event → Verify in inbox → Acknowledge → Verify removed

def test_concurrent_ingestion():
    # 1000 concurrent requests → all succeed

def test_spike_recovery():
    # 1K req/sec → 10K req/sec → 1K req/sec → latency normalizes
```

### Load Tests

```python
def test_10k_req_sec_for_5_minutes():
    # Sustained 10K req/sec with <100ms p95 latency

def test_mixed_read_write_workload():
    # 80% POST /events, 20% GET /inbox → all meet SLAs
```

---

## Deployment Plan

### Pre-Deployment
1. Deploy code to staging environment
2. Warm up Lambda (invoke 10x to eliminate cold starts)
3. Populate inbox with test data (1000+ events)
4. Verify CloudWatch dashboards are operational
5. Set up performance results storage (S3, DynamoDB)

### Test Execution
1. Smoke test: 100 req/sec × 30 sec (should complete <2 min)
2. Baseline load test: 1K req/sec × 2 min (should complete <5 min)
3. Spike test: Ramp 0 → 5K → 0 (should complete <5 min)
4. Full load test: 10K req/sec × 5 min (should complete <15 min with ramp)
5. Results analysis: Automated Python script generates report

### Rollback Plan
- If p95 latency >200ms: Stop test, investigate code/config
- If error rate >1%: Stop test, check for errors in logs
- If DynamoDB throttling: Increase capacity and rerun
- If Lambda throttling: Increase concurrency and rerun

---

## Definition of Done

A story is considered complete when:

1. **Load Testing Framework**
   - [ ] Locust scripts created for all test scenarios
   - [ ] Load test can generate 10K req/sec (verified with dry-run)
   - [ ] Results captured (latency percentiles, error rate, throughput)
   - [ ] Can run locally or via CI/CD pipeline

2. **Performance Verification**
   - [ ] Load test completed: 10K req/sec × 5 min
   - [ ] Throughput verified: ≥9.99M events (99.9% success)
   - [ ] p95 latency verified: <100ms for POST /events
   - [ ] p95 latency verified: <50ms for GET /inbox
   - [ ] Error rate verified: <0.1% throughout test
   - [ ] DynamoDB metrics verified: No throttling
   - [ ] Lambda metrics verified: <1000 concurrent executions

3. **Auto-Scaling Validation**
   - [ ] DynamoDB auto-scaling policy configured
   - [ ] Lambda concurrency limits configured (min: 10, max: 1000)
   - [ ] Spike test completed and recovery verified
   - [ ] No throttling errors during spike recovery

4. **Performance Baselines Documented**
   - [ ] Baseline report created (`PERFORMANCE_BASELINE.md`)
   - [ ] All metrics documented: latency, throughput, error rate, cost
   - [ ] Historical tracking configured
   - [ ] Regression detection alerts enabled

5. **CI/CD Integration**
   - [ ] GitHub Actions workflow created
   - [ ] Smoke test runs on every push (<1 min)
   - [ ] Baseline test runs nightly
   - [ ] Full load test runs on demand
   - [ ] Results stored and accessible

6. **Documentation**
   - [ ] Load testing guide created (`LOAD_TESTING_GUIDE.md`)
   - [ ] Performance targets documented
   - [ ] Baseline report generated
   - [ ] Scripts documented (how to run locally, interpret results)

7. **Production Readiness**
   - [ ] Monitoring dashboard operational
   - [ ] Alerts configured (latency >150ms, error rate >0.5%)
   - [ ] Runbooks updated with performance baselines
   - [ ] Team trained on performance monitoring

---

## Risk Assessment and Mitigation

### Testing Risks

**Risk: Load Test Crashes Production Environment**
- Impact: Service outage, customer impact
- Probability: Low (staging used for testing)
- Mitigation: Always test in staging first, use separate AWS account if possible
- Testing: Dry-run with 100 users before full load

**Risk: Bottleneck Not Identified During Testing**
- Impact: Production performance issues after launch
- Probability: Medium (may need larger test load)
- Mitigation: Run tests at 2x expected production load
- Testing: Monitor all AWS services during test (Lambda, DynamoDB, SQS)

**Risk: Performance Regression After Code Changes**
- Impact: API degradation undetected until production
- Probability: Medium (without automated testing)
- Mitigation: Automated regression tests in CI/CD
- Testing: Compare baselines between commits

### Infrastructure Risks

**Risk: DynamoDB Throttling Under Load**
- Impact: Increased latency, errors
- Probability: Medium (if capacity not sized correctly)
- Mitigation: Verify auto-scaling configured, start with higher capacity
- Testing: Monitor ConsumedWriteCapacityUnits during test

**Risk: Lambda Concurrency Limit Reached**
- Impact: Requests queued and delayed
- Probability: Low (1000 limit is generous)
- Mitigation: Monitor ConcurrentExecutions during test
- Testing: Alert if concurrency >900

---

## Change Log

| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-11-11 | 1.0 | Created Story 1.10 with load testing and performance specifications | Scrum Master |

---

