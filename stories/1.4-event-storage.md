# Story 1.4: Implement Event Storage with DynamoDB

**Epic:** Epic 1: Build Zapier Triggers API MVP
**Story ID:** 1.4
**Status:** Ready for Development
**Priority:** High
**Story Points:** 8
**Sprint:** TBD

---

## User Story

**As a** System Architect,
**I want** to persistently store events in DynamoDB,
**so that** events are not lost and can be reliably delivered to workflows.

---

## Context and Background

This story completes the event storage infrastructure for the Zapier Triggers API. While Stories 1.1 and 1.2 provisioned the initial DynamoDB tables and implemented basic event persistence, this story focuses on:

1. **Validation**: Verify DynamoDB schema, indexes, and configuration match specifications
2. **DynamoDB Streams Integration**: Enable real-time event change notifications for downstream delivery
3. **Advanced Features**: Point-in-time recovery, TTL validation, capacity planning
4. **Testing & Monitoring**: Comprehensive testing of storage layer, performance validation, CloudWatch metrics
5. **Operational Readiness**: Ensure production-grade reliability and disaster recovery

**Dependencies:**
- Story 1.1: Core Infrastructure (DynamoDB tables created)
- Story 1.2: Event Ingestion (EventRepository implemented with basic persistence)
- Story 1.3: Authentication and Authorization (API key validation)

**Related Documentation:**
- PRD Section 2.4: "Database Integration Strategy"
- Architecture Section 8: Database Schema (DynamoDB Events Table, Streams, TTL)
- Architecture Section 7.1: Event Ingestion and Delivery Workflow (shows DynamoDB Streams integration)

---

## Acceptance Criteria

### AC1: DynamoDB Table Schema Verified
**Given** the DynamoDB events table has been created in Story 1.1
**When** the schema is inspected
**Then** the following structure is confirmed:
- Primary Key: Partition Key `user_id` (String), Sort Key `timestamp#event_id` (String)
- All required attributes present: event_id, event_type, payload, status, timestamp, ttl, retry_count, metadata
- Data types correct: payload stored as Map (JSON), status as String enum, retry_count as Number
- GSI-1 (EventTypeIndex) exists: user_id (PK) + event_type#timestamp (SK)
- GSI-2 (StatusIndex) exists: user_id (PK) + status#timestamp (SK)

**Implementation Notes:**
- Run AWS CLI `describe-table` to inspect schema
- Verify all attributes listed in Architecture Section 8.1
- Confirm projections set to ALL for both GSIs
- Check billing mode (On-Demand for MVP)
- Document schema validation results

---

### AC2: Global Secondary Index for Event Type Queries
**Given** the EventTypeIndex GSI exists
**When** a query is executed filtering by user_id and event_type
**Then** the index is used efficiently (no table scans)
**And** query performance is <50ms for typical result sets (100-1000 events)
**And** the index projection includes all necessary attributes for GET /inbox responses

**Implementation Notes:**
- Create test queries:
  - `query(user_id='test-user', event_type='user.created')`
  - `query(user_id='test-user', event_type='order.completed')`
- Measure query latency with CloudWatch Insights
- Verify projection: `ProjectionExpression: 'ALL'` or explicitly list required fields
- No table scans should appear in CloudWatch logs for /inbox queries

---

### AC3: TTL Configured for 30-Day Event Expiration
**Given** the DynamoDB TTL feature is enabled on the events table
**When** an event is stored with ttl attribute set to (current_unix_time + 30 days)
**Then** events are automatically deleted after 30 days
**And** the deletion process is verified with test events
**And** TTL configuration can be confirmed via AWS API

**Implementation Notes:**
- TTL Attribute: `ttl` (Number, Unix timestamp)
- Enable TTL via AWS CLI: `aws dynamodb update-time-to-live --table-name zapier-triggers-api-events-{env} --time-to-live-specification AttributeName=ttl,Enabled=true`
- Test: Create event with ttl=now+30 days, wait/verify deletion (or use backdated ttl for faster testing)
- Archive strategy: Optional Lambda function triggered by DynamoDB Streams to copy expired items to S3 before deletion
- Document TTL deletion rates in CloudWatch dashboard

---

### AC4: DynamoDB Streams Enabled for Event Notifications
**Given** DynamoDB Streams is enabled on the events table
**When** an event is created or updated
**Then** a stream record is generated with NEW_IMAGE (event data)
**And** stream records can be consumed by downstream processors (Lambda workers for delivery)
**And** stream ARN is available for integration with SQS/SNS/Lambda

**Implementation Notes:**
- Enable Streams via Terraform (modified in Story 1.1):
  ```hcl
  stream_specification {
    stream_view_type = "NEW_IMAGE"  # Only new state needed
  }
  ```
- Stream ARN format: `arn:aws:dynamodb:us-east-1:ACCOUNT:table/zapier-triggers-api-events-{env}/stream/2025-11-11T10:00:00.000`
- View type: NEW_IMAGE (shows updated item after modification)
- Alternative: Use SQS queue already in place (Story 1.2) as primary event delivery mechanism
- Document decision: DynamoDB Streams for high-volume, low-latency scenarios; SQS for reliability/retries

---

### AC5: Write Capacity Auto-Scaling Configured (5-100 WCU)
**Given** the DynamoDB table is configured for on-demand or provisioned billing
**When** event ingestion load varies
**Then** write capacity scales automatically between 5 and 100 WCU
**And** scaling policies are configured in CloudWatch or Terraform
**And** no throttling occurs during normal load (0-1000 events/sec)

**Implementation Notes:**
- For On-Demand billing (recommended for MVP):
  - No manual scaling needed; pay per request
  - Unlimited WCU scaling with burst capacity
- For Provisioned Billing (if cost-optimizing):
  - Minimum: 5 WCU (5 writes/second)
  - Maximum: 100 WCU (100 writes/second)
  - Configure with `aws autoscaling` or Terraform `aws_appautoscaling_target` and `aws_appautoscaling_policy`
- Test: Simulate 10,000 events/sec load, verify no throttling (ConsumedWriteCapacityUnits < max)
- Monitor: CloudWatch metric `ConsumedWriteCapacityUnits` and `UserErrors` (throttling)

---

### AC6: Read Capacity Auto-Scaling Configured (5-100 RCU)
**Given** the DynamoDB table is configured for provisioned read capacity
**When** GET /inbox and query operations are executed
**Then** read capacity scales automatically between 5 and 100 RCU
**And** scaling policies respond within 1-2 minutes to load changes
**And** no throttling occurs during GET /inbox queries

**Implementation Notes:**
- Similar to AC5, for provisioned mode:
  - Minimum: 5 RCU (5 reads/second)
  - Maximum: 100 RCU (100 reads/second)
  - Use `aws_appautoscaling_target` for DynamoDB read capacity
- For On-Demand mode: Automatic, no configuration needed
- Test: Execute 100+ concurrent GET /inbox queries, verify latency <50ms
- GSI auto-scaling: Configure separately if using provisioned mode on GSIs

---

### AC7: Point-in-Time Recovery Enabled for Disaster Recovery
**Given** point-in-time recovery (PITR) is enabled on the events table
**When** data corruption or accidental deletion occurs
**Then** the table can be restored to any point in time within 35 days
**And** recovery can be initiated via AWS Console or CLI

**Implementation Notes:**
- Enable via AWS CLI: `aws dynamodb update-continuous-backups --table-name zapier-triggers-api-events-{env} --point-in-time-recovery-specification PointInTimeRecoveryEnabled=true`
- Or via Terraform:
  ```hcl
  point_in_time_recovery {
    enabled = true
  }
  ```
- Retention: Default 35 days (maximum supported by AWS)
- Restore creates new table (original remains unchanged)
- Test: Document restore procedure (will not perform actual restore during story, but procedure must be documented)
- Cost: Minimal (backup storage included in DynamoDB pricing)
- Monitoring: Confirm status via AWS Console or `describe-table` command

---

## Integration Verification (IV)

### IV1: Event Write Operations Complete with <10ms p95 Latency

**Verification Checklist:**
- [ ] Single event write to DynamoDB measured with CloudWatch Insights
- [ ] p95 latency confirmed <10ms (actual write operation time, excluding network)
- [ ] p99 latency confirmed <20ms
- [ ] No DynamoDB throttling observed (ConsumedWriteCapacityUnits < provisioned WCU)
- [ ] Concurrent write test (100+ simultaneous writes) shows latency remains <10ms
- [ ] SQS send latency measured separately (should be <5ms)
- [ ] Total event ingestion latency (validation + DynamoDB + SQS) <35ms p95

**How to Verify:**

```bash
# View DynamoDB write latency metrics
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name SuccessfulRequestLatency \
  --dimensions Name=TableName,Value=zapier-triggers-api-events-dev \
            Name=Operation,Value=PutItem \
  --start-time 2025-11-11T10:00:00Z \
  --end-time 2025-11-11T11:00:00Z \
  --period 60 \
  --statistics Average,Maximum

# CloudWatch Insights query for custom latency tracking
fields @duration, @timestamp
| filter @message like /Event created successfully/
| stats pct(@duration, 95) as p95_latency, pct(@duration, 99) as p99_latency by bin(5m)
```

**Expected Results:**
- Actual DynamoDB write: 8-12ms
- SQS send: 3-8ms
- Total p95: 25-35ms (excluding Lambda cold start)

---

### IV2: DynamoDB Metrics Monitored in CloudWatch Dashboard

**Verification Checklist:**
- [ ] CloudWatch dashboard created or updated with DynamoDB metrics
- [ ] Dashboard includes the following widgets:
  - ConsumedReadCapacityUnits (over time)
  - ConsumedWriteCapacityUnits (over time)
  - UserErrors (throttling count)
  - SuccessfulRequestLatency (PutItem operation)
  - ItemCount (total events in table)
  - StorageSize (total table size)
- [ ] Alarms configured for:
  - ConsumedWriteCapacityUnits > 80% of provisioned (if provisioned mode)
  - UserErrors > 0 (any throttling)
  - SuccessfulRequestLatency > 20ms p99
- [ ] Dashboard refreshes automatically (5-min intervals)
- [ ] Historical metrics visible (last 24 hours minimum)

**How to Verify:**

```bash
# List existing dashboards
aws cloudwatch list-dashboards

# View dashboard definition
aws cloudwatch get-dashboard --dashboard-name zapier-triggers-api-dev

# Create sample dashboard (or update existing)
aws cloudwatch put-dashboard \
  --dashboard-name zapier-triggers-api-dev \
  --dashboard-body file://dashboard-config.json
```

**Sample Dashboard Widget (JSON):**
```json
{
  "type": "metric",
  "properties": {
    "metrics": [
      ["AWS/DynamoDB", "ConsumedWriteCapacityUnits", {"stat": "Average"}],
      [".", "ConsumedReadCapacityUnits", {"stat": "Average"}],
      [".", "UserErrors", {"stat": "Sum"}],
      [".", "SuccessfulRequestLatency", {"stat": "p95"}]
    ],
    "period": 300,
    "stat": "Average",
    "region": "us-east-1",
    "yAxis": {"left": {"min": 0}},
    "title": "DynamoDB Events Table Metrics"
  }
}
```

---

### IV3: TTL Deletion Process Validated with Test Events

**Verification Checklist:**
- [ ] Test event created with backdated ttl (now - 1 second)
- [ ] Event written to DynamoDB successfully
- [ ] Wait 5-10 minutes for TTL background job to run
- [ ] Verify event is deleted via table query
- [ ] CloudWatch metric `UserErrors` or custom metric shows deletion occurred
- [ ] Multiple test cycles (at least 3 test events with different timestamps)
- [ ] Archive process (if implemented): Verify expired items copied to S3 before deletion

**How to Verify:**

```bash
# Create test event with expired TTL
aws dynamodb put-item \
  --table-name zapier-triggers-api-events-dev \
  --item '{"user_id": {"S": "test-ttl"}, "timestamp#event_id": {"S": "2025-11-01T10:00:00Z#test-id"}, "event_id": {"S": "test-id"}, "ttl": {"N": "1000000000"}, "status": {"S": "received"}, "event_type": {"S": "test"}, "payload": {"M": {}}}'

# Query before TTL deletion (should exist)
aws dynamodb query \
  --table-name zapier-triggers-api-events-dev \
  --key-condition-expression "user_id = :uid" \
  --expression-attribute-values '{"uid": {"S": "test-ttl"}}' \
  --projection-expression "event_id, timestamp#event_id"

# Wait 5+ minutes for TTL background job

# Query after TTL deletion (should be empty)
aws dynamodb query \
  --table-name zapier-triggers-api-events-dev \
  --key-condition-expression "user_id = :uid" \
  --expression-attribute-values '{"uid": {"S": "test-ttl"}}' \
  --projection-expression "event_id, timestamp#event_id"

# Result: Items should be empty after TTL expiration
```

**Expected Results:**
- Before TTL: 1 item returned
- After TTL: 0 items returned (QueryResponse with Items=[])
- CloudWatch metric: See increase in `TTLDeletedItemCount` (if exposed by AWS)

---

## Technical Implementation Details

### Technology Stack
- **Database:** Amazon DynamoDB (serverless, managed)
- **Monitoring:** Amazon CloudWatch Logs, Metrics, Dashboards
- **Infrastructure:** Terraform (created in Story 1.1, enhanced in this story)
- **Testing:** Python pytest with moto (DynamoDB mock)
- **Tools:** AWS CLI for verification and testing

### Key Components to Validate/Enhance

#### 1. Terraform DynamoDB Module (Enhanced from Story 1.1)

**File:** `infrastructure/terraform/modules/dynamodb/main.tf`

Ensure the following configurations exist:

```hcl
resource "aws_dynamodb_table" "events" {
  name           = "zapier-triggers-api-events-${var.environment}"
  billing_mode   = "PAY_PER_REQUEST"  # On-Demand (MVP)
  hash_key       = "user_id"
  range_key      = "timestamp#event_id"

  attribute {
    name = "user_id"
    type = "S"
  }

  attribute {
    name = "timestamp#event_id"
    type = "S"
  }

  attribute {
    name = "event_type"
    type = "S"
  }

  attribute {
    name = "status"
    type = "S"
  }

  # Global Secondary Index for event_type queries
  global_secondary_index {
    name            = "EventTypeIndex"
    hash_key        = "user_id"
    range_key       = "event_type#timestamp"
    projection_type = "ALL"
  }

  # Global Secondary Index for status queries
  global_secondary_index {
    name            = "StatusIndex"
    hash_key        = "user_id"
    range_key       = "status#timestamp"
    projection_type = "ALL"
  }

  # TTL Configuration
  ttl {
    attribute_name = "ttl"
    enabled        = true
  }

  # Point-in-Time Recovery
  point_in_time_recovery {
    enabled = true
  }

  # DynamoDB Streams for change data capture
  stream_specification {
    stream_view_type = "NEW_IMAGE"
  }

  tags = {
    Name        = "zapier-triggers-api-events"
    Environment = var.environment
    Terraform   = "true"
  }
}
```

#### 2. DynamoDB Streams Integration

**Purpose:** Enable real-time event notifications for downstream processing

**Implementation Approach:**
- DynamoDB Streams generates stream records when events are created/updated
- Stream records contain NEW_IMAGE (complete event data)
- Stream can be consumed by:
  - Lambda function (via EventSourceMapping) - for real-time processing
  - SQS queue (via Kinesis Consumer Library) - for buffering
  - S3 (for archival of old events before TTL deletion)

**For MVP:** Use existing SQS queue (from Story 1.2) as primary; document Streams for Phase 2

**Enable in Terraform:**
```hcl
# Enable streams in dynamodb_table resource (shown above)
stream_specification {
  stream_view_type = "NEW_IMAGE"
}

# Get stream ARN from Terraform output
output "events_table_stream_arn" {
  value = aws_dynamodb_table.events.stream_arn
}
```

#### 3. EventRepository Enhancement (from Story 1.2)

**File:** `services/api/src/repositories/event_repository.py`

**Verify:**
- All write operations use `put_item` correctly
- Query operations use GSIs appropriately
- TTL field is set on every write: `ttl = int((datetime.utcnow() + timedelta(days=30)).timestamp())`
- Error handling for throttling and capacity issues
- Metadata included: source_ip, api_version, correlation_id

**Sample Enhanced Method:**

```python
def create(self, event: Event, user_id: str) -> Event:
    """Create a new event with TTL and metadata."""
    import time
    from datetime import datetime, timedelta

    # Calculate TTL (30 days from now, Unix timestamp)
    ttl = int((datetime.utcnow() + timedelta(days=30)).timestamp())

    # Build item with all required attributes
    item = event.dict()
    item['user_id'] = user_id
    item['timestamp#event_id'] = f"{event.timestamp}#{event.event_id}"
    item['ttl'] = ttl

    try:
        self.table.put_item(Item=item)
        logger.info(f"Event {event.event_id} persisted with TTL {ttl}")
        return event
    except self.dynamodb.meta.client.exceptions.ProvisionedThroughputExceededException:
        logger.error(f"DynamoDB throttled - write capacity exceeded")
        raise
    except Exception as e:
        logger.exception(f"Failed to persist event: {e}")
        raise
```

#### 4. Testing Enhancements

**Files:** `services/api/tests/integration/test_dynamodb_storage.py` (new)

**Test Coverage:**
- DynamoDB table schema validation
- TTL behavior (events deleted after 30 days)
- GSI query performance
- Concurrent writes (no throttling)
- Error handling (throttling, item too large)
- Stream record generation (if implementing in this story)

**Sample Test:**

```python
import pytest
from datetime import datetime, timedelta
import time

@pytest.mark.integration
def test_event_ttl_expiration():
    """Verify events are deleted after TTL expires."""
    repo = EventRepository()

    # Create event with backdated TTL (expired)
    event = Event(
        event_id="test-ttl-123",
        user_id="test-user",
        event_type="test.event",
        payload={},
        status="received",
        timestamp=datetime.utcnow().isoformat() + "Z"
    )

    # Manually set expired TTL
    repo.table.put_item(
        Item={
            **event.dict(),
            'user_id': 'test-user',
            'timestamp#event_id': f"{event.timestamp}#{event.event_id}",
            'ttl': int(time.time()) - 1000  # Expired
        }
    )

    # Verify event exists
    result = repo.get_by_id('test-user', 'test-ttl-123')
    assert result is not None

    # In production, wait for TTL cleanup (5+ minutes)
    # For testing, we document the expected behavior
    print("TTL deletion is background process - manual verification required in prod")
```

#### 5. Monitoring and Alerting

**CloudWatch Alarms to Configure:**

```python
# Via boto3 or Terraform
alarms = [
    {
        'AlarmName': 'DynamoDB-WriteCapacity-High',
        'MetricName': 'ConsumedWriteCapacityUnits',
        'Statistic': 'Average',
        'Period': 60,
        'EvaluationPeriods': 5,
        'Threshold': 80,  # Alert if >80% of provisioned
        'ComparisonOperator': 'GreaterThanThreshold',
        'Namespace': 'AWS/DynamoDB'
    },
    {
        'AlarmName': 'DynamoDB-Throttling',
        'MetricName': 'UserErrors',
        'Statistic': 'Sum',
        'Period': 60,
        'EvaluationPeriods': 1,
        'Threshold': 1,  # Alert on any throttling
        'ComparisonOperator': 'GreaterThanOrEqualToThreshold'
    }
]
```

---

## Testing Strategy

### Unit Tests (Event Repository with moto)

**File:** `services/api/tests/unit/repositories/test_event_repository_storage.py`

Test areas:
1. Schema validation (item structure)
2. TTL field calculation
3. Error handling (throttling, size limits)
4. GSI queries (EventTypeIndex, StatusIndex)

```python
@pytest.fixture(autouse=True)
def setup_dynamodb(monkeypatch):
    import moto
    with moto.mock_dynamodb():
        yield
```

### Integration Tests

**File:** `services/api/tests/integration/test_dynamodb_storage.py`

Test areas:
1. End-to-end event creation → DynamoDB persistence → TTL expiration
2. GSI query performance and correctness
3. Concurrent writes (simulating 1000 events/sec)
4. Large payload handling (near 1MB limit)

### Performance Tests

**File:** `services/api/tests/load/test_dynamodb_throughput.py`

Test areas:
1. Measure p95 write latency
2. Verify no throttling under 10,000 events/sec
3. Capacity utilization monitoring
4. Concurrent read (GET /inbox) performance

```python
from locust import HttpUser, task, between

class DynamoDBStorageTest(HttpUser):
    wait_time = between(0.1, 0.5)

    @task
    def create_and_query_events(self):
        # POST event
        response = self.client.post("/v1/events", json={...})

        # GET /inbox to query
        response = self.client.get("/v1/inbox")
```

---

## Deployment Plan

### Pre-Deployment Checklist
- [ ] Terraform modules updated with DynamoDB enhancements
- [ ] All tests passing locally (unit + integration)
- [ ] Schema verified against Architecture Document Section 8.1
- [ ] CloudWatch dashboard created
- [ ] Alarms configured (high write capacity, throttling, latency)
- [ ] TTL test completed (or plan documented for post-deployment)
- [ ] Disaster recovery procedure documented

### Deployment Steps
1. Run `terraform plan` for dev environment
2. Review changes: table modifications, TTL, PITR
3. Apply: `terraform apply -target=aws_dynamodb_table.events`
4. Verify: `aws dynamodb describe-table --table-name zapier-triggers-api-events-dev`
5. Enable TTL: `aws dynamodb update-time-to-live ...` (if not in Terraform)
6. Enable Streams: Verify stream configuration in Console
7. Run smoke tests: Create event → Verify in DynamoDB → Query with GSI
8. Monitor CloudWatch for 1 hour before promoting to staging

### Rollback Plan
- DynamoDB table modifications are typically non-destructive
- If TTL incorrectly configured: Disable TTL, restore table from backup (PITR)
- If capacity settings problematic: Switch to On-Demand (no data loss)
- If schema issue discovered: Create new table, migrate data with Lambda

---

## Definition of Done

A story is considered complete when:

1. **Schema Validation**
   - [ ] DynamoDB table schema verified (partition/sort keys, attributes, GSIs)
   - [ ] Schema matches Architecture Document Section 8.1 exactly
   - [ ] All indexes created and active
   - [ ] Table can accept and persist events correctly

2. **Configuration Complete**
   - [ ] TTL enabled and tested (or test plan documented)
   - [ ] Point-in-time recovery enabled
   - [ ] DynamoDB Streams enabled (NEW_IMAGE view type)
   - [ ] Billing mode configured (On-Demand for MVP)
   - [ ] If using provisioned: auto-scaling configured (5-100 WCU/RCU)

3. **Testing Complete**
   - [ ] Unit tests for EventRepository (TTL, schema, error handling)
   - [ ] Integration tests for event creation → persistence → retrieval
   - [ ] TTL deletion validation (manual test or documented procedure)
   - [ ] Performance tests confirm <10ms p95 latency for writes
   - [ ] No DynamoDB throttling observed under target load

4. **Monitoring & Alerting**
   - [ ] CloudWatch dashboard created with DynamoDB metrics
   - [ ] Alarms configured for throttling, high latency, capacity warnings
   - [ ] Logs structured with correlation IDs for troubleshooting

5. **Documentation**
   - [ ] DynamoDB schema documented in README or architecture notes
   - [ ] TTL cleanup process documented (if background job created)
   - [ ] Disaster recovery procedure documented (PITR restore steps)
   - [ ] Runbook created for common DynamoDB issues
   - [ ] CloudWatch Insights queries documented for troubleshooting

6. **Integration**
   - [ ] EventRepository methods tested with real DynamoDB access patterns
   - [ ] GSI queries verified for /inbox endpoint (Story 1.5 dependency)
   - [ ] DynamoDB Streams integrated with delivery mechanism (SQS or Lambda)
   - [ ] Monitoring integrated with existing CloudWatch dashboard

7. **Code Quality**
   - [ ] All acceptance criteria met
   - [ ] Integration Verification points validated
   - [ ] Code follows repository pattern (data access isolated)
   - [ ] Error handling comprehensive (throttling, validation, TTL)
   - [ ] Logging includes correlation IDs and structured JSON format

---

## Risk Assessment and Mitigation

### Technical Risks

**Risk:** DynamoDB hot partition if events unevenly distributed by user_id
- **Mitigation:** Use composite partition key with randomized suffix in Phase 2; implement adaptive capacity
- **Current Mitigation:** Monitor ConsumedWriteCapacityUnits for uneven distribution
- **Monitoring:** CloudWatch metric showing per-partition metrics
- **Trigger for Escalation:** If throttling >10 events/min despite adequate capacity

**Risk:** Lambda cold start + DynamoDB latency exceeds 100ms p95 target
- **Mitigation:** Optimize function size; use provisioned concurrency; measure DynamoDB latency separately
- **Verification:** Measure DynamoDB write latency in isolation <10ms; Lambda overhead <20ms
- **If Occurs:** Increase Lambda memory, enable provisioned concurrency for critical functions

**Risk:** TTL background cleanup takes >30 days, items linger longer than expected
- **Mitigation:** AWS typically deletes within 48 hours; archive old items to S3 before TTL fires
- **Verification:** CloudWatch metric shows TTL deletion timing; manual test confirms
- **Impact if Occurs:** Slightly higher storage costs; no data loss or availability impact

### Operational Risks

**Risk:** Point-in-time recovery (PITR) not actually enabled despite configuration
- **Mitigation:** Test restore procedure (create test table from backup)
- **Verification:** AWS Console shows continuous backups status = "ENABLED"
- **If Fails:** Re-enable PITR via AWS CLI or Terraform; verify completion before closing story

**Risk:** DynamoDB Streams not properly integrated with event delivery system
- **Mitigation:** For MVP, use existing SQS queue; phase in Streams consumption in Phase 2
- **Current Approach:** SQS is primary, Streams is optional enhancement
- **If Implementing Streams:** Create Lambda event source mapping to consume stream records

**Risk:** Terraform apply changes table configuration incorrectly
- **Mitigation:** Run `terraform plan` first; review changes carefully; test in dev before prod
- **Safety Check:** Schema validation test runs after `terraform apply`

### Data Risks

**Risk:** Event data exceeds DynamoDB item size limit (400KB for single attribute)
- **Mitigation:** Enforce 1MB total item size; payload size validated in Story 1.2 (max 1MB payload)
- **Verification:** No DynamoDB ItemSizeTooLarge errors observed
- **If Occurs:** Reject events >1MB at API layer (already implemented)

**Risk:** TTL deletion removes data without proper archival for compliance
- **Mitigation:** Implement optional S3 archival before TTL deletion via Streams Lambda
- **Current:** Optional enhancement; MVP deletes after 30 days per spec
- **Compliance:** Ensure data deletion aligns with GDPR/data retention policy

---

## Success Criteria

Story 1.4 is successful when:

1. **Functional:** DynamoDB table fully configured per Architecture Document Section 8.1
2. **Reliable:** 99.9% of events persist successfully; TTL cleanup verified
3. **Fast:** Event write operations complete <10ms p95 latency
4. **Observable:** CloudWatch metrics and alarms monitor table health
5. **Recoverable:** Point-in-time recovery enabled and restore procedure documented
6. **Testable:** Comprehensive tests validate schema, TTL, GSI queries, performance

---

## Notes and Open Questions

### Open Questions

1. **DynamoDB Streams vs SQS:** Should we implement Streams-to-Lambda for event delivery, or continue using SQS?
   - **Decision:** MVP uses SQS (Story 1.2); Streams is optional Phase 2 enhancement for ultra-low-latency delivery
   - **Reasoning:** SQS provides retry semantics and dead-letter queue; Streams adds complexity
   - **Trade-off:** Streams = instant; SQS = <1sec latency with retries

2. **Archive to S3:** Should expired events be copied to S3 before TTL deletion?
   - **Decision:** Optional; not MVP requirement but valuable for compliance audits
   - **Recommendation:** Document Lambda function for Phase 2 that triggers on Streams for expired items

3. **GSI Provisioning:** If using provisioned billing mode, should GSIs have separate capacity?
   - **Decision:** Use same provisioned capacity as table (5-100 WCU/RCU) for simplicity
   - **Recommendation:** Switch to On-Demand for MVP to eliminate scaling complexity

4. **Backup Frequency:** How often should PITR backups be taken?
   - **Decision:** AWS handles automatically; continuous backups for 35 days default
   - **Cost:** Minimal (<1% of table cost typically)

### Additional Context

**Related Stories:**
- Story 1.2 (Event Ingestion): Uses EventRepository to write to DynamoDB
- Story 1.5 (Event Inbox): Queries events using GSIs created in this story
- Story 1.7 (Retry & Status): Updates event status, relies on DynamoDB updates

**Future Enhancements (Phase 2):**
- DynamoDB Streams → Lambda for real-time event delivery (sub-100ms)
- Automatic S3 archival of expired events for compliance
- Multi-region replication for disaster recovery
- DynamoDB DAX (in-memory cache) for hot read paths if needed
- Custom partition key sharding for extreme scale (>10,000 events/sec sustained)

---

## Appendix: DynamoDB Operations Reference

### Create/Verify Table

```bash
# Describe table schema
aws dynamodb describe-table --table-name zapier-triggers-api-events-dev

# List all tables
aws dynamodb list-tables

# Check TTL status
aws dynamodb describe-time-to-live --table-name zapier-triggers-api-events-dev

# View continuous backups (PITR)
aws dynamodb describe-continuous-backups --table-name zapier-triggers-api-events-dev
```

### Query Examples

```bash
# Query by user_id + event_type (using EventTypeIndex)
aws dynamodb query \
  --table-name zapier-triggers-api-events-dev \
  --index-name EventTypeIndex \
  --key-condition-expression "user_id = :uid AND begins_with(event_type#timestamp, :et)" \
  --expression-attribute-values '{":uid": {"S": "user-123"}, ":et": {"S": "user.created"}}' \
  --limit 50

# Query by user_id + status (using StatusIndex)
aws dynamodb query \
  --table-name zapier-triggers-api-events-dev \
  --index-name StatusIndex \
  --key-condition-expression "user_id = :uid AND begins_with(status#timestamp, :st)" \
  --expression-attribute-values '{":uid": {"S": "user-123"}, ":st": {"S": "received"}}' \
  --limit 50
```

### Monitoring

```bash
# CloudWatch Insights query - write latency
fields @timestamp, @duration, event_id
| filter ispresent(@duration)
| stats avg(@duration) as avg_ms, pct(@duration, 95) as p95_ms, pct(@duration, 99) as p99_ms

# Consumed capacity trend
aws cloudwatch get-metric-statistics \
  --namespace AWS/DynamoDB \
  --metric-name ConsumedWriteCapacityUnits \
  --dimensions Name=TableName,Value=zapier-triggers-api-events-dev \
  --start-time 2025-11-10T00:00:00Z \
  --end-time 2025-11-12T00:00:00Z \
  --period 3600 \
  --statistics Average,Maximum
```

### TTL Testing

```bash
# Enable TTL (if not already enabled)
aws dynamodb update-time-to-live \
  --table-name zapier-triggers-api-events-dev \
  --time-to-live-specification AttributeName=ttl,Enabled=true

# Create test item with expired TTL
aws dynamodb put-item \
  --table-name zapier-triggers-api-events-dev \
  --item '{
    "user_id": {"S": "test-ttl-user"},
    "timestamp#event_id": {"S": "2025-11-01T10:00:00Z#test-event-id"},
    "event_id": {"S": "test-event-id"},
    "event_type": {"S": "test.event"},
    "status": {"S": "received"},
    "payload": {"M": {}},
    "ttl": {"N": "1000000000"}
  }'

# Wait 5+ minutes, then verify deletion
aws dynamodb query \
  --table-name zapier-triggers-api-events-dev \
  --key-condition-expression "user_id = :uid" \
  --expression-attribute-values '{":uid": {"S": "test-ttl-user"}}'
```

---

**End of Story 1.4: Implement Event Storage with DynamoDB**
